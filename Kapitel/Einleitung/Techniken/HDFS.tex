\subsection{Hadoop Distributed File System}

Das \textit{Hadoop Distributed File System (HDFS)} ist ein verteiltes und fehlertolerantes Dateisystem.
Es wurde designt um auf Hardware mit geringen Kosten zu laufen und große Datenmengen zu verarbeiten.
Im HDFS gespeicherte Dateien können von einem Gigabyte bis mehrere Terabyte groß sein.
Außerdem unterstützt HDFS die replizierte Speicherung von Dateien mit einem beliebigen Faktor.

Das Dateisystem ist ähnlich zu anderen bekannten Dateisystem.
Dateien und Ordner können im Namensraum hierarchisch organisiert werden.
Es unterstützt jedoch keine Zurgiffsberechtigung oder Hard- und Soft-Links.
Um einfach und effektiv kohärent zu bleiben, werden Dateien nur einmal geschrieben, können aber mehrfach gelesen werden.
Dateien werden zur Speicherung in einzelne Blöcke aufgeteilt.
Dabei sind für eine Datei alle, bis auf der letzte, Blöcke gleich groß.

Ein HDFS-Cluster funktioniert nach dem Master-Worker-Prinzip und besteht aus einem NameNode und vielen DataNodes.
Der NameNode übernimmt die Verwaltung des Namensraum und Verteilung der einzelnen Blöcke einer Datei.
Er reguliert dazu noch den Zugriff durch Clients und führt Operationen auf dem Dateisystem, wie das Öffnen, Schließen oder Umbenennen von Ordnern und Dateien aus.
Die DataNodes speichern die einzelnen Blöcke der Dateien.
Auf die Anweisung des NameNodes führen sie die Erstellung, Löschung und Replikation von Blöcken aus.
Außerdem bearbeiten sie Anfragen zum Lesen und Schreiben von Dateien \parencite{hdfs}.