\subsection{Apache Spark}
\label{sec:spark}

Apache Spark ist eine Datenverabeitungs-Engine.
Das ist Ziel ist die Vereinheitlichung von Arbeitsabläufen.
Darunter fallen zum Beispiel Arbeiten mit SQL, Datenströmen, maschinellem Lernen oder Graphen-Daten.
Es gibt Bibliotheken für diese oder andere Arbeitsabläufe, die durch ihre Optimierung in Spark ähnliche Performance, wie spezialisierte Engines erreichen.
Spark kann entweder lokal auf einem Computer oder auf einem Spark-Cluster nach dem Master-Worker-Modell ausgeführt werden.

Ein Kernprinzip ist die Abstraktion der Daten in RDDs (Resilient Distributed Datasets, deutsch: Robuste Verteilte Datensätze).
RDDs sind fehlertolerante Sammlungen von Objekten, die auf den Workern verteilt werden und parallel bearbeitet werden können.
Diese werden flüchtig im Speicher gehalten, können aber für einen schnelleren Zugriff zwischengespeichert werden.
Die Erstellung und Bearbeitung von RDDs geschieht über sogenannte Transformationen.
Die Transformationen werden in einem Herkunftsgraphen gespeichert, wodurch eine Wiederherstellung bei Fehler an jedem Punkt möglich ist.

Für die Verarbeitung von strukturierten oder semi-strukturierten Daten gibt es zusätzlich die eigene Abfragesprache SparkSQL.
Spark biete APIs für die Sprachen Scala, Java, Python und R.
Auf den RDDs gibt es noch eine weitere Abstraktionsebene.
Mit DataFrames, die eine Sammlung RDDs von Datensätzen mit einem bekannten Schema sind, kann eine API benutzt werden, bei der die Bearbeitung der Daten über Funktionsaufrufe statt SparkSQL möglich ist \parencite{spark}.

Die Interaktion mit einem Spark Cluster kann über eine interaktive Shell oder als fertige Anwendung geschehen.
Informationen über die Anwendung werden im SparkContext gespeichert.
Beim Lesen und Schreiben wird das Format der Daten angegeben.
Spark unterstützt standardmäßig einige Formate, aber durch die Konfiguration von extra Bibilotheken im SparkContext, können beliebige Formate hinuzgefügt werden.
Von der verwendet Bibilothek sind auch die Optionen abhängig, die beim Lesen und Schreiben gesetzt werden müssen.
Die Optionen sind immer Schlüssel-Wert-Paare und enthalten zum Beispiel Verbindungsinformationen zu einer Datenbank oder einen Dateispeicherort \parencite{spark-website}.
