\section{Interner Datenspeicher}

Die Entwicklung einer eigenen Lösung zum Speichern von Daten mit Versionierung passt nicht in den zeitlichen Rahmen dieser Arbeit.
Daher wird der Delta Lake verwendet, da dieser alle benötigten Funktionenfür die Versionierung bietet und eine voll unterstützte Schnittstelle zu Spark hat.
Da das System auf eigenen Server laufen soll, wird als Speicher für den Delta Lake ein HDFS Cluster verwendet.
Auch die Quelldateien der Ingestion und die Plugins können im HDFS abgelegt werden und sind damit für alle Microservices abrufbar.
Der Zugriff zum Speichern der Daten geschieht über den Delta Lake beziehungsweise Spark und für die Quelldateien und Plugins über die WebHDFS REST-Schnittstelle.

Neben den versionierten müssen auch Daten mit und ohne Struktur gespeichert werden.
Auch hierfür wird das HDFS verwendet.
Strukturierte und semistrukturierte Daten können im Parquet Format abgelegt werden.
Das ist das gleiche Format, das auch der Delta Lake verwendet.
Werden so wie sie hochgeladen wurden im HDFS abgelegt.

Die Ordner werden folgendermaßen organisiert.
Für alle Daten wird im Root-Verzeichniss des HDFS ein Ordner "datalake" angelegt.
Dieser enthält die Unterordner für die Hochgeladenen Quell-Dateien "`sources"', die Plugins "`plugins"' und die geladenen Daten "`data"'.
In den Ordnern "`sources"' und "`plugins'" werden dann für jede Datenquelle Ordner mit deren Id angelegt, in denen die hochgeladenen Dateien abgelegt werden.
Für die geladenen Daten wird nocheinmal und die Ordner "`structured"' für Daten mit Struktur, "´unstructured'" für unstrukturierte Daten und "`delta'" für die Delta Tabellen angelegt.
Diese unterteilen sich dann ebenfalls wieder in Ordner für jede Datenquelle mit der Id als Name.
