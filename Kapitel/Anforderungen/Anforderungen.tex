\chapter{Anforderungen}
\label{sec:anf}

Basierend auf der Zielsetzung (\cref{sec:ziel}) können die Anforderungen erarbeitet werden, nach denen die Ingestion-Schnittstelle entwickelt werden soll.
Dafür werden nachfolgend die Ziele in einzelne Abschnitte aufgeteilt.
In diesen Abschnitt wird das Ziel nochmal genauer erläutert und die einzelnen Anforderungen herausgearbeitet.
Auf die Erfüllung der Ziele und Anforderungen wird dann nochmal in der Evaluierung und Zusammenfassung eingegangen.

\section{Quellen- und Formatunabhänigkeit}
\label{sec:anf-unab}
Am HIT werden verschiedenste Daten verarbeitet.
Viele kommen aus Datenbanksystemen oder Dateien.
Es gibt aber auch spezielle Systeme, die ihre Daten nur über eine REST-API zur Verfügung stellen.
Alle diese Daten sollen mit der Ingestion-Schnittstelle geladen und gespeichert werden können.
Dazu muss diese sowohl Daten entgegen nehmen als auch aus Systemen extrahieren können und im Data-Lake-System muss ein Speicher integriert sein, der Daten aus allen Strukturen und Formaten speichern kann.
Um eine Flexibilität auch beim Einsatz des Systems in einer anderen Umgebung zu gewährleisten soll nicht nur der interne, sondern auch externe Systeme zum Speichern der Daten verwendet werden können.

\paragraph{ANF\_01}
\label{ANF_01}
Die Schnittstelle muss in der Lage sein Quelldaten entgegen zu nehmen, die an das Data-Lake-System gesendet werden.
Diese müssen so verwaltet werden, dass sie über Apache Spark gelesen werden können.

\paragraph{ANF\_02}
\label{ANF_02}
Da Apache Spark nicht von sich aus in der Lage ist, alle Datenformate zu verstehen, muss es möglich sein, die SparkSession mit benötigten Paketen zu erweitern.

\paragraph{ANF\_03}
\label{ANF_03}
Für die Unterstützung verschiedenster Quell- und Zielspeicher verwendet Apache Spark zum Lesen und Speichern einen Format-Parameter und variable Optionen.
Diese sollen komplett konfigurierbar sein um alle Systeme verwenden zu können.

\paragraph{ANF\_04}
\label{ANF_04}
Einige Quellen, zum Beispiel eine REST-API können nicht direkt über Spark in ein DataFrame gelesen werden.
Daher muss eine Möglichkeit geben werden, die Ingestion zur Laufzeit um eigenen Programmcode zu erweitern, der ein DataFrame manuell aus einer Reihe von Abfragen aufbaut.

\section{Kontinuierliches Laden}
\label{sec:anf-ci}
Da Daten sich mit der Zeit ändern, soll die Ingestion-Schnittstelle in der Lage sein, neue Daten aus einer Datenquelle, die bereits aufgenommen wurde, erneut zu laden.
Die Implementierung soll das erneute Anstoßen, eine Zeitsteuerung oder Datenströme zulassen.

\paragraph{ANF\_05}
\label{ANF_05}
Es soll möglich sein, Datenströme in das Data-Lake-System zu integrieren und als Quelle für kontinuierliche Daten zu verwenden.

\paragraph{ANF\_06}
\label{ANF_06}
Um aktuelle Daten aus Datenquellen, die nicht über einen Datenstrom verfügen, zu integrieren, soll es eine  wiederholte Ausführung mit einer Zeitsteuerung geben.

\paragraph{ANF\_07}
\label{ANF_07}
Es wird ein API-Endpunkt benötigt, über den die Ingestion für eine bestimmte Datenquelle angestoßen werden kann.
Dieser soll auch dazu verwendet werden, externe Systeme, wie eigene CDC-Lösungen anzubinden.

\paragraph{ANF\_08}
\label{ANF_08}
Eine gleichzeitige Ausführung mehrerer Ingestions auf der gleichen Datenquelle könnte leicht zu Konflikten in den Daten führen.
Daher soll sichergestellt werden, dass das System diesen Fall nicht zulässt.


Wie bereits erwähnt, ist der Prototyp des Data-Lake-Systems eine monolithische Anwendung.
Das bedeutet, die gesamte Anwendung ist als Komplettlösung in einem Programm entwickelt und bereitgestellt worden.
Solche Ansätze sind Anfangs leichter umzusetzen, haben aber größere Nachteile in Bereichen wie Fehlertoleranz und Wartbarkeit.
Daher soll für die Ingestion-Schnittstelle der Microservice-Ansatz verfolgt werden.
Hierbei werden die Funktionalitäten und Aufgaben auf mehrere kleinere Anwendungen aufgeteilt.
Das hat, wie von \textcite{microservices} dargestellt, mehrere Vorteile.
Die Wartung fällt bei mehreren kleinen Programmen leichter, da sie übersichtlicher und verständlicher sind.
Bei Fehlfunktionen einzelner Mircoservices fällt außerdem nicht die komplette Anwendung aus, sondern nur die Funktion, für die der Service zuständig war.
Zuletzt ist es einfacher bestimmte Aspekte der Software zu skalieren und bei Updates bleibt eine höhere Verfügbarkeit, da nur ein kleiner Teil des Systems neu gestartet werden muss.

\section{Datenversionierung}
\label{sec:anf-vers}
Die Änderungen, die an Daten gemacht werden, sind wichtige Informationen, um weitere Verarbeitungen oder Analysen zu optimieren.
Gerade durch die kontinuierliche Ingestion von neuen Daten am HIT entsteht eine Vielzahl solcher Änderungen.
Dabei gibt es zwei verschiedene Arten, wie Änderungen in das Data-Lake-System eingespielt werden können.
Die erste Art ist die Ingestion von Daten aus einer externen Change-Data-Capture-Lösung (\cref{sec:cdc}) als Änderungen an einer Datenquelle, die bereits ins System geladen wurde.
Bei der zweiten Art wird eine Datenquelle, die bereits geladen wurde, ein weiteres mal geladen.
Hierbei ist es notwendig, das die Ingestion-Schnittstelle die Änderungen zwischen den beiden Ständen erkennen kann.
Die Änderungen an den Daten im System sollen über eine Versionierung nachvollziehbar gespeichert werden.

\paragraph{ANF\_09}
\label{ANF_09}
Das System soll eine Möglichkeit bieten, Änderungen an Daten als Versionen zu speichern und zur Abfrage zur Verfügung zu stellen.
Außerdem sollen damit auch die Daten zu bestimmten Zeitpunkten rekonstruierbar sein.

\paragraph{ANF\_10}
\label{ANF_10}
Um für alle eingehenden Daten die Möglichkeit der Versionierung im System anbieten zu können, muss eine CDC-Implementierung eingebaut werden, die für jede Datenquelle ausgeführt werden kann.

\paragraph{ANF\_11}
\label{ANF_11}
Auch die Verwendung einer eigenen CDC-Lösung für eine Datenquelle soll unterstützt werden.
Dazu muss eine Quelle mit Änderungsdaten für eine bereits aufgenommen Datenquelle erstellt werden können.

\section{Datenversionierung}
\label{sec:anf-metadata}
Metadaten spielen eine wichtige Rolle bei der Qualität der geladen Daten.
Die Ingestion-Ebene kann schon beim Laden der Daten Metadaten erfassen.
Für diese wird ein Metadatenmodell benötigt, dass alle Metadaten abbildet, die bei der Ingestion erfasst werden können.

\paragraph{ANF\_12}
\label{ANF_12}
Die Ingestion soll beim Laden der Daten Metadaten erfassen.

\paragraph{ANF\_13}
\label{ANF_13}
Das Metadatenmodell soll alle Informationen enthalten, die bei der Ingestion gesammelt werden können.

\section{Architektur}
\label{sec:anf-arch}
Die Architektur soll die Ingestion in Mircoservices umgesetzt werden.
Außerdem wird eine Schnittstelle für die Interaktion mit dem System benötigt.
Daraus ergeben sich folgende Anforderungen, an die Architektur.

\paragraph{ANF\_14}
\label{ANF_14}
Die Interaktionsschnittstelle mit dem System soll eine REST-API sein, die in das aktuelle Prototyp-System integriert werden soll.

\paragraph{ANF\_15}
\label{ANF_15}
Durch eine klare Trennung der Aufgaben der Microservices soll deren Überschneidungen und Abhängigkeiten so gering wie möglich gehalten werden.

\paragraph{ANF\_16}
\label{ANF_16}
Für die Kommunikation zwischen den Microservices soll eine einheitliche Lösung verwendet werden.
Diese soll es auch ermöglichen neue Mircoservices einfach in die Architektur einzubringen.

